{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/michaelbai/ML/dataset/flickr30k_images/results.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/michaelbai/ML/dataset/flickr30k_images/flickr30k_images/2609797461.jpg'),\n",
       " PosixPath('/Users/michaelbai/ML/dataset/flickr30k_images/flickr30k_images/1788892671.jpg')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_comments_folder = Path(\"/Users/michaelbai/ML/dataset/flickr30k_images\")\n",
    "image_comments_file = image_comments_folder / \"results.csv\" \n",
    "images_folder = image_comments_folder / \"flickr30k_images\"\n",
    "print(image_comments_file)\n",
    "list(images_folder.glob(\"*.jpg\"))[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1000092795.jpg'], '1000092795.jpg')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(image_comments_file, sep=\"|\", index_col=False)\n",
    "df = df.astype({'image_name': 'str', 'comment_number': int, 'comment': str})\n",
    "df1 = df[0: 1]\n",
    "list(df1[\"image_name\"]), df1[\"image_name\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0078, 0.0118,  ..., 0.8588, 0.8706, 0.8667],\n",
       "         [0.0157, 0.0118, 0.0196,  ..., 0.8941, 0.8314, 0.8549],\n",
       "         [0.0118, 0.0157, 0.0196,  ..., 0.9490, 0.9098, 0.8392],\n",
       "         ...,\n",
       "         [0.6510, 0.7059, 0.5098,  ..., 0.4157, 0.5255, 0.4196],\n",
       "         [0.7922, 0.5647, 0.5216,  ..., 0.6157, 0.6118, 0.6157],\n",
       "         [0.5647, 0.7255, 0.7216,  ..., 0.6118, 0.7490, 0.4157]],\n",
       "\n",
       "        [[0.0235, 0.0235, 0.0196,  ..., 0.9569, 0.9922, 0.9765],\n",
       "         [0.0314, 0.0196, 0.0275,  ..., 0.9922, 0.9608, 0.9922],\n",
       "         [0.0118, 0.0157, 0.0196,  ..., 1.0000, 1.0000, 0.9608],\n",
       "         ...,\n",
       "         [0.6941, 0.7373, 0.6078,  ..., 0.6196, 0.6745, 0.6392],\n",
       "         [0.8588, 0.6863, 0.6275,  ..., 0.7373, 0.7294, 0.7686],\n",
       "         [0.6157, 0.8275, 0.8392,  ..., 0.7294, 0.7843, 0.4941]],\n",
       "\n",
       "        [[0.0157, 0.0196, 0.0157,  ..., 0.9765, 1.0000, 0.9804],\n",
       "         [0.0275, 0.0157, 0.0235,  ..., 0.9804, 0.9961, 1.0000],\n",
       "         [0.0118, 0.0157, 0.0196,  ..., 1.0000, 0.9843, 0.9804],\n",
       "         ...,\n",
       "         [0.5765, 0.5137, 0.3922,  ..., 0.3373, 0.4431, 0.2824],\n",
       "         [0.5922, 0.4510, 0.4588,  ..., 0.5059, 0.4863, 0.4588],\n",
       "         [0.3412, 0.6745, 0.5961,  ..., 0.4784, 0.6000, 0.2549]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img = Image.open(\"/Users/michaelbai/ML/dataset/flickr30k_images/flickr30k_images/1000092795.jpg\")\n",
    "convert_tensor = transforms.ToTensor()\n",
    "convert_tensor(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Image\n",
    "    img_width_size = 400\n",
    "    img_height_size = 400\n",
    "\n",
    "    # Text\n",
    "    max_text_len = 50\n",
    "\n",
    "def load_image_tensor(config: Config, img_file_path: Path) -> torch.tensor:\n",
    "    # Load image from file\n",
    "    img = Image.open(img_file_path)\n",
    "    print()\n",
    "    print(f\"img: {img}\")\n",
    "    \n",
    "    # Convert to tensor\n",
    "    convert_tensor = transforms.ToTensor()\n",
    "    image_tensor = convert_tensor(img)\n",
    "\n",
    "    # resize base on config\n",
    "    resize = transforms.Resize(size=(config.img_height_size, config.img_width_size))\n",
    "    image_tensor = resize(image_tensor)\n",
    "    return image_tensor\n",
    "\n",
    "# Create Dataset \n",
    "class ImgCommentDataset(Dataset):\n",
    "    def __init__(self, config: Config,  img_comments_folder: Path, train_test_split: str = \"train\", train_test_split_portion: float = 0.8):\n",
    "        self.config = config\n",
    "        self.img_commments_folder = img_comments_folder\n",
    "        self.img_comments_file = img_comments_folder / \"results.csv\"\n",
    "        self.imgs_folder = img_comments_folder / \"flickr30k_images\"\n",
    "        \n",
    "        self.train_test_split = train_test_split\n",
    "        self.train_test_split_portion = train_test_split_portion\n",
    "\n",
    "        # The current `results.csv` file is using \"| \" to seperate 3 columns. \n",
    "        # For the pd.read_csv, the `sep` here is given as a regular expression. \n",
    "        df = pd.read_csv(self.img_comments_file, sep=\"|\")\n",
    "        train_split_len = int(len(df)*self.train_test_split_portion)\n",
    "        if self.train_test_split == \"train\":\n",
    "            self.img_comments_df = df[:train_split_len]\n",
    "        else:\n",
    "            self.img_comments_df = df[train_split_len:]\n",
    "        \n",
    "        self.text_encoder = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.img_comments_df)\n",
    "    \n",
    "    def __getitem__(self, idx:int):\n",
    "        print(f\"idx: {idx}\")\n",
    "        row_df = self.img_comments_df[idx: idx+1]\n",
    "        image_name = str(list(row_df[\"image_name\"])[0])\n",
    "        assert (self.imgs_folder/image_name).is_file(), f\"cannot find file: {self.img_commments_folder/image_name}\"\n",
    "\n",
    "        comment_number = int(list(row_df[\"comment_number\"])[0])\n",
    "        comment = str(list(row_df[\"comment\"])[0])\n",
    "        comment_encoding = self.text_encoder.encode(comment)\n",
    "        if len(comment_encoding) > self.config.max_text_len:\n",
    "            comment_encoding = comment_encoding[:self.config.max_text_len]\n",
    "        else:\n",
    "            # TODO: review append `<|im_end|>` - 200265 logic\n",
    "            comment_encoding = comment_encoding + [200265 for _ in range(self.config.max_text_len - len(comment_encoding))]\n",
    "        assert len(comment_encoding) == self.config.max_text_len\n",
    "        comment_encoding = torch.tensor(comment_encoding, dtype=torch.int)\n",
    "        \n",
    "        # return load_image_tensor(self.imgs_folder/image_name), comment_number, comment, comment_encoding\n",
    "        image_tensor = load_image_tensor(self.config, self.imgs_folder/image_name)\n",
    "\n",
    "        return image_tensor, comment_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127132 31783\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "\n",
    "train_dataset = ImgCommentDataset(config, image_comments_folder, train_test_split=\"train\", train_test_split_portion=0.8)\n",
    "test_dataset = ImgCommentDataset(config, image_comments_folder, train_test_split=\"test\", train_test_split_portion=0.8)\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
